{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZfkG0mLeIUl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_boston()\n",
        "feature_names = data.feature_names\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['MEDV'] = pd.Series(data.target)\n",
        "df_X=df.drop('MEDV', axis=1, inplace=False)\n",
        "df_Y=df['MEDV']"
      ],
      "metadata": {
        "id": "A0B2sPrkeMoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93740ff5-1704-4bc5-898f-1306ef43e3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_reg_rmsearray=[]\n",
        "for i in range(1,8,1):\n",
        "  poly = PolynomialFeatures(degree= i, include_bias=False)\n",
        "  poly_features = poly.fit_transform(df_X)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(poly_features, df_Y, test_size=0.4, random_state=1)\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
        "  poly_reg_model = LinearRegression()\n",
        "  poly_reg_model.fit(X_train, y_train)\n",
        "  poly_reg_y_predicted = poly_reg_model.predict(X_val)\n",
        "  poly_reg_rmse = np.sqrt(mean_squared_error(y_val, poly_reg_y_predicted))\n",
        "  poly_reg_rmsearray.append(poly_reg_rmse)"
      ],
      "metadata": {
        "id": "Pg02awAqmI7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(poly_reg_rmsearray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wohplBmbvmcK",
        "outputId": "9180c45a-689b-41a5-f807-c87c47c19943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.456971927684733, 5.707016121069094, 75.68075671685065, 259.70721960205583, 291.3397813754658, 221.44143413912627, 226.15136714697434]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly = PolynomialFeatures(degree= 1, include_bias=False)\n",
        "poly_features = poly.fit_transform(df_X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(poly_features, df_Y, test_size=0.4, random_state=1)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
        "poly_reg_model = LinearRegression()\n",
        "poly_reg_model.fit(X_train, y_train)\n",
        "poly_reg_y_predicted = poly_reg_model.predict(X_test)\n",
        "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, poly_reg_y_predicted))\n",
        "poly_reg_rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXgF0dZHv8RK",
        "outputId": "5069938b-784c-4489-fd8e-022712d173bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.547289065278924"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        " \n",
        "alphaarray=[0.00001,0.0001,0.001,0.01,0.1] \n",
        "for i in alphaarray:\n",
        "  lasso = Lasso(alpha=i, max_iter=10e5)\n",
        "  lasso.fit(X_train,y_train)\n",
        "  train_score=lasso.score(X_train,y_train)\n",
        "  test_score=lasso.score(X_test,y_test) \n",
        "  print ('training score for alpha= ' + str(i) + ' :' , train_score) \n",
        "  print ('test score for alpha = ' + str(i) + ' :' , test_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCelCi_v6UEd",
        "outputId": "d735597d-520f-4aa6-dd35-d26cf3970b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training score for alpha= 1e-05 : 0.7468316515844864\n",
            "test score for alpha = 1e-05 : 0.7366333554323465\n",
            "training score for alpha= 0.0001 : 0.746831609061166\n",
            "test score for alpha = 0.0001 : 0.7366212347000438\n",
            "training score for alpha= 0.001 : 0.7468273562228122\n",
            "test score for alpha = 0.001 : 0.7364961612391743\n",
            "training score for alpha= 0.01 : 0.7464028354764276\n",
            "test score for alpha = 0.01 : 0.7348628113960634\n",
            "training score for alpha= 0.1 : 0.7324473082335632\n",
            "test score for alpha = 0.1 : 0.7156255257568283\n"
          ]
        }
      ]
    }
  ]
}